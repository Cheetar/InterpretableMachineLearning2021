{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Wczytanie danych od Shumee\n",
    "data = pd.read_excel(\"shumee_mckinsey -Aktualizacja 01.03.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na razie ograniczę się tylko do produktów sprzedanych w Polsce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"Kraj\"]==\"PL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzam poprawność danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba NaN w każdej kolumnie: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID zamówienia         0\n",
       "Data                  0\n",
       "Źródło              229\n",
       "Kraj                  0\n",
       "Miasto              270\n",
       "Kod Pocztowy        311\n",
       "Nazwa produktu        0\n",
       "SKU               13175\n",
       "EAN               14328\n",
       "Ilość               112\n",
       "Cena                112\n",
       "Waluta              112\n",
       "Koszt dostawy       112\n",
       "Forma dostawy      3544\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Liczba NaN w każdej kolumnie: \")\n",
    "data.isna().agg(\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usunę te wiersze, w których nie ma ceny (jest to tylko 112 wierszy, więc nie tracę dużo danych usuwając je)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data[\"Cena\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz załaduję model Word2Vec. Wykorzsytuję bibliotekę Gensim, oraz model wytrenowany m.in. na polskiej Wikipedii, który można pobrać pod tym adresem: https://github.com/sdadas/polish-nlp-resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PiotrGrabysz\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade gensim\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec = KeyedVectors.load(\"./word2vec/word2vec_100_3_polish.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec zamienia słowa na wektory (w tym przypadku wektory wymiaru 100). Na przykład słowu \"krzesło\" odpowiada taki wektor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.012289e+00,  1.462072e+00, -5.004100e+00, -3.441711e+00,\n",
       "        3.990560e-01, -2.565111e+00,  5.030282e+00,  6.047542e+00,\n",
       "        4.548630e+00,  1.738084e+00, -2.758710e-01, -7.522800e-02,\n",
       "        1.855085e+00, -6.247217e+00, -5.888261e+00, -8.400401e+00,\n",
       "       -2.965125e+00, -3.482589e+00,  4.830710e-01, -1.018867e+00,\n",
       "       -8.132490e-01, -3.048696e+00,  4.958340e+00, -1.293860e-01,\n",
       "       -3.085849e+00, -1.863563e+00, -5.953629e+00,  4.385289e+00,\n",
       "        1.279462e+00, -1.170168e+00, -8.543170e-01, -4.681480e-01,\n",
       "        5.515535e+00, -7.276000e-03,  7.161128e+00,  3.059943e+00,\n",
       "        2.034154e+00,  3.861800e-01,  2.643000e+00, -7.206631e+00,\n",
       "       -2.734934e+00,  4.014585e+00,  3.858501e+00, -5.677879e+00,\n",
       "        4.270895e+00,  6.786670e-01,  3.034365e+00,  1.110994e+00,\n",
       "       -4.248924e+00,  2.391838e+00,  2.946400e-02,  1.036666e+00,\n",
       "        5.377800e-01, -5.942716e+00, -4.273711e+00, -1.379860e+00,\n",
       "        2.706288e+00,  2.586019e+00,  3.046250e+00,  1.442850e-01,\n",
       "        2.344921e+00,  2.700333e+00, -3.828824e+00, -2.492035e+00,\n",
       "       -2.816570e+00, -8.655730e-01, -9.096200e-01,  1.111703e+00,\n",
       "        2.977318e+00,  8.109150e-01,  1.862500e-02,  4.680109e+00,\n",
       "       -1.131898e+00, -3.702902e+00,  2.898683e+00,  2.101025e+00,\n",
       "       -3.736189e+00, -5.678101e+00, -3.525910e-01,  7.479200e-01,\n",
       "       -1.773977e+00, -1.363426e+00,  3.593656e+00,  3.630788e+00,\n",
       "        1.863202e+00, -5.153527e+00,  1.361373e+00, -1.006270e-01,\n",
       "       -2.530103e+00, -5.022254e+00,  1.696438e+00, -1.698829e+00,\n",
       "        3.305116e+00,  3.534354e+00,  3.875269e+00, -1.359292e+00,\n",
       "        3.383750e-01, -1.931999e+00, -1.322408e+00,  5.337275e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec[\"krzesło\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na podstawie takiej wektorowej reprezentacji można wyszukać słowa o najbardziej podobnym znaczeniu do danego słowa.\n",
    "\n",
    "Słowa podobne do \"krzesło\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('stołek', 0.9247931241989136), ('taboret', 0.9213142991065979), ('fotel', 0.9031204581260681), ('kanapa', 0.8804746270179749), ('krzesełko', 0.8769845962524414), ('sofa', 0.8673840165138245), ('zydel', 0.8485152125358582), ('tapczan', 0.8382896780967712), ('otomana', 0.8218340277671814), ('szezlong', 0.8153223991394043)]\n"
     ]
    }
   ],
   "source": [
    "print(word2vec.similar_by_word(\"krzesło\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oraz słowa podobne do słowa \"komputer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('oprogramowanie', 0.799543559551239), ('sterownik', 0.794553279876709), ('kalkulator', 0.7934095859527588), ('skaner', 0.7867334485054016), ('urządzenie', 0.7822620868682861), ('laptop', 0.7730702757835388), ('drukarka', 0.7705292105674744), ('procesor', 0.7685826420783997), ('czytnik', 0.7645211219787598), ('serwer', 0.7605681419372559)]\n"
     ]
    }
   ],
   "source": [
    "print(word2vec.similar_by_word(\"komputer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_names = data[\"Nazwa produktu\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_names = [\n",
    "    [word for word in name.lower().split()]\n",
    "    for name in data[\"Nazwa produktu\"].to_list()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzę zbiór wszystkich słów wykorzystanych w nazwach produktów. Wszystkie wielkie litery zastępuję małymi literami, bo tylko takie słowa są rozpoznawane przez word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_set = set()\n",
    "\n",
    "stoplist = []\n",
    "for name in data[\"Nazwa produktu\"].to_list():\n",
    "    for word in name.lower().split():\n",
    "        words_set.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33708"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W nazwach produktów użyto 33708 różnych słów. Być może niektóre z nich, np oznaczające wymiary (jak 10x10), trzeba będzie odrzucić."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Słowa które znalazły się w banku słów word2vec:\n",
    "included_words = []\n",
    "# Słowa których word2vec nie zna\n",
    "removed_words = []\n",
    "# lista wektorów odpowiadających poszeczególnym słowom\n",
    "words_array = []\n",
    "\n",
    "for word in words_set:\n",
    "    try:\n",
    "        vec = word2vec[word]\n",
    "        words_array.append(vec)\n",
    "        included_words.append(word)\n",
    "    except KeyError:\n",
    "        removed_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Udało się zakodować 9190\n",
      "24518 słów nie znalazło się w bazie słów\n"
     ]
    }
   ],
   "source": [
    "print(f\"Udało się zakodować {len(included_words)}\")\n",
    "print(f\"{len(removed_words)} słów nie znalazło się w bazie słów\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "words_array = np.array(words_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.122328"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(words_array[1, :] - words_array[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.759961,  1.117283, -0.107931, -0.152149, -2.290422, -0.172126,\n",
       "        4.05315 , -1.791256, -1.659794,  0.4952  , -2.806745, -2.546781,\n",
       "       -0.571918,  2.483599, -1.154938, -1.144642, -1.997079,  2.778277,\n",
       "       -4.63895 ,  3.812113, -2.464403, -0.661001,  1.018622, -8.009574,\n",
       "        0.163577,  1.77995 ,  1.08292 ,  2.203077,  1.701301,  2.771147,\n",
       "       -1.84412 , -3.020437,  5.353816,  1.048164,  2.296658, -0.811624,\n",
       "        0.300312,  2.013064, -1.484625,  2.062446, -1.034696,  2.141481,\n",
       "        3.774813, -2.611755,  1.802854,  2.16944 , -1.446178,  1.244814,\n",
       "        2.497016, -0.842132, -3.307101, -3.557271,  1.294654, -0.25647 ,\n",
       "        0.022632,  1.007145,  1.610226, -3.296503,  3.143573,  1.180332,\n",
       "       -4.1695  ,  5.196706,  2.109448, -0.790676,  0.711407,  3.816041,\n",
       "        0.636172, -3.780181,  2.575389, -4.240666, -3.64649 , -0.419408,\n",
       "       -1.553977,  0.79523 , -2.492866, -0.30542 , -1.775612, -0.205165,\n",
       "        0.837055,  3.297613, -0.948421,  0.43182 ,  0.75525 , -0.929318,\n",
       "        1.572179,  2.374792, -0.766407,  0.265101, -1.565082, -0.640802,\n",
       "       -0.355541, -0.804873,  1.263874,  0.728597, -2.449992, -0.810424,\n",
       "       -0.680006,  0.939928, -1.168842, -2.280534], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_array[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klastrowanie za pomocą DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7080588"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.similarity(\"flanela\", \"flanelowy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29194117]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.pairwise_distances(X = word2vec[\"flanela\"].reshape(1,-1), Y = word2vec[\"flanelowy\"].reshape(1,-1), metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = DBSCAN(eps=0.25, min_samples = 10, metric = \"cosine\").fit(words_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klastry: \n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, -1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Klastry: \")\n",
    "print(set((clustering.labels_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# Słownik w którym kluczami są słowa, a wartościami numer klastra w którym znajduje się to słowo\n",
    "word2cluster = dict()\n",
    "\n",
    "# Słownik w którym kluczem jest numer klastra, a wartością lista słów w klastrze\n",
    "cluster2word = collections.defaultdict(list)\n",
    "\n",
    "for idx, word in enumerate(included_words):\n",
    "    word2cluster[word] = clustering.labels_[idx]\n",
    "    cluster2word[clustering.labels_[idx]].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers: 6412\n",
      "cluster 0: 770\n",
      "cluster 1: 882\n",
      "cluster 2: 746\n",
      "cluster 3: 95\n",
      "cluster 4: 113\n",
      "cluster 5: 22\n",
      "cluster 6: 19\n",
      "cluster 7: 11\n",
      "cluster 8: 26\n",
      "cluster 9: 10\n",
      "cluster 10: 42\n",
      "cluster 11: 11\n",
      "cluster 12: 15\n",
      "cluster 13: 9\n",
      "cluster 14: 7\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of outliers: {len(cluster2word[-1])}\")\n",
    "for i in range(len(cluster2word) - 1):\n",
    "    print(f\"cluster {i}: {len(cluster2word[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem jest taki, że niektóre klastry są bardzo małe. Z drugiej strony niektóre z nich wydaja się bardzo sensowne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster(cluster):\n",
    "    words_long_string = \"\"\n",
    "    for word in cluster:\n",
    "        words_long_string += word\n",
    "        words_long_string += \", \"\n",
    "    print(words_long_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klaster samochodów\n",
      "cadillac, hatchback, saab, citroen, motocykl, gti, willys, kombi, scuderia, wrangler, aventador, opel, sedan, mazda, peugeot, mercedes, favorit, meriva, gt, ciągnik, autobus, narty, unimog, dodge, arrinera, tiguan, hulajnoga, traktor, volkswagen, sanie, ambulans, bmw, cruiser, nissan, porsche, pojazd, aygo, volvo, roomster, sanki, cars, przyczepa, seat, terenówka, yaris, helikopter, transporter, metalic, samochód, karoq, rower, jaguar, konie, rover, passat, garaż, kangoo, ciężarówka, lamborghini, ferrari, wóz, fiat, hummer, wagon, corolla, skuter, lotus, wózek, śmieciarka, sportage, audi, speedster, bugatti, combi, aut, vario, maserati, kabriolet, trabant, chevrolet, touran, toyota, vw, renault, jeep, charger, ford, auto, samolot, touareg, kodiaq, rowerek, stonic, buick, suv, \n"
     ]
    }
   ],
   "source": [
    "print(\"Klaster samochodów:\")\n",
    "print_cluster(cluster2word[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klaster włoskich słów:\n",
      "balenciaga, giulia, fiori, arianna, iglesias, colle, raffaele, verona, enrico, dimas, matera, emporio, morales, alves, revlon, arnaldo, gucci, cattaneo, salerno, palermo, salinas, rinascimento, lopez, lecco, caserta, milano, escada, bustamante, dkny, fabia, carbone, flavia, trapani, felice, suarez, acqua, pezzo, narciso, pomar, diavolo, rivera, ricci, bari, habana, lagerfeld, prato, prisma, modena, fano, gilmar, enrique, chiavari, vallejo, americano, puig, ragusa, bianco, federica, mario, roberto, estrella, ronaldo, herrera, moschino, catania, versace, cacharel, armani, missoni, giorgio, biagiotti, carlo, siena, sibilla, cavalli, toscana, cristiano, gabbana, parma, diamanti, fratelli, andria, rojo, dino, rodriguez, renato, carrara, brito, cerruti, prada, arturo, savona, diego, luca, chanel, novara, ruiz, salvatore, ignacio, francesco, gio, antonio, asfora, trussardi, camil, escalante, valeria, capello, gino, conca, rossi, tronto, pedro, \n"
     ]
    }
   ],
   "source": [
    "print(\"Klaster włoskich słów:\")\n",
    "print_cluster(cluster2word[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klaster Amerykańskich miast:\n",
      "denver, wichita, wisconsin, peoria, kansas, milwaukee, dallas, vermont, rockford, cedar, tucson, detroit, fresno, chicago, georgia, kalifornia, michigan, boston, minnesota, seattle, iowa, hartford, \n"
     ]
    }
   ],
   "source": [
    "print(\"Klaster Amerykańskich miast:\")\n",
    "print_cluster(cluster2word[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klaster określeń kształtu:\n",
      "owalny, naroże, sześciokątny, okrągły, trójkątny, poprzeczny, prostokąt, zakrzywiony, podłużny, schodkowy, skośny, stożkowy, prostokątny, kolumnowy, kwadratowy, półokrągły, cylindryczny, kwadrat, płaski, \n"
     ]
    }
   ],
   "source": [
    "print(\"Klaster określeń kształtu:\")\n",
    "print_cluster(cluster2word[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klaster (zdrobnionych) zwierząt:\n",
      "kociak, pieski, zwierzak, niedźwiadek, bobas, kaczuszka, kota, zwierzątko, piesek, małpka, maluch, \n"
     ]
    }
   ],
   "source": [
    "print(\"Klaster (zdrobnionych) zwierząt:\")\n",
    "print_cluster(cluster2word[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klaster zwierząt:\n",
      "pies, wilk, królik, hipopotam, kaczka, słoń, kot, troll, nosorożec, smok, leniwiec, tygrys, mysz, zając, żółw, lampart, niedźwiedź, jeleń, małpa, wiewiórka, myszy, brontozaur, krokodyl, wąż, pantera, żyrafa, \n"
     ]
    }
   ],
   "source": [
    "print(\"Klaster zwierząt:\")\n",
    "print_cluster(cluster2word[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klaster (łacińskich?) słów:\n",
      "movit, velit, editi, quid, postquam, vinum, magno, grati, legere, aio, \n"
     ]
    }
   ],
   "source": [
    "print(\"Klaster (łacińskich?) słów:\")\n",
    "print_cluster(cluster2word[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klaster francuskich słów:\n",
      "clinique, un, univers, chefs, bien, professionnel, champagne, poudre, visionnaire, que, ses, tous, cuisine, nouvel, parfum, chaud, reve, fantome, curso, fils, roue, boxe, classique, ou, petit, mais, vertus, soleil, etoile, adorable, espanol, oiseau, elle, parisienne, absolue, plume, noms, jaune, homme, jeune, lumineuse, c'est, \n"
     ]
    }
   ],
   "source": [
    "print(\"Klaster francuskich słów:\")\n",
    "print_cluster(cluster2word[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klaster zbitek liter:\n",
      "pj, bi, jt, jb, jj, pbd, ia, q, aq, xq, uz, \n"
     ]
    }
   ],
   "source": [
    "print(\"Klaster zbitek liter:\")\n",
    "print_cluster(cluster2word[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klaster biżuterii:\n",
      "zapinka, bransoletka, kolczyk, amulet, breloczek, bransoletki, paciorki, koraliki, perła, klips, diadem, pierścionek, naszyjnik, brelok, wisiorek, \n"
     ]
    }
   ],
   "source": [
    "print(\"Klaster biżuterii:\")\n",
    "print_cluster(cluster2word[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klaster imion:\n",
      "emil, gustav, heiko, sven, oskar, fischer, anton, klaus, otto, \n"
     ]
    }
   ],
   "source": [
    "print(\"Klaster imion:\")\n",
    "print_cluster(cluster2word[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klaster określeń kształtu:\n",
      "vida, viento, sono, paloma, soy, agua, siempre, \n"
     ]
    }
   ],
   "source": [
    "print(\"Klaster hiszpańskich słów:\")\n",
    "print_cluster(cluster2word[14])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
